{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d28b694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D,MaxPooling2D, Flatten\n",
    "import keras\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, Adamax, RMSprop, SGD, Adadelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d36576",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ec44b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8ba326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5adf8eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(x_train.min(), x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ca06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "x_train=x_train.astype('float32')/255.0\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=tf.keras.utils.to_categorical(y_train,100)\n",
    "y_test=tf.keras.utils.to_categorical(y_test,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c39aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "963c8f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.min(), x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c8c0a75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 02:57:36.177986: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 13s 8ms/step - loss: 3.9355 - accuracy: 0.0911 - val_loss: 3.4100 - val_accuracy: 0.1838\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 3.2250 - accuracy: 0.2100 - val_loss: 3.0269 - val_accuracy: 0.2548\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.8942 - accuracy: 0.2749 - val_loss: 2.8395 - val_accuracy: 0.2949\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.6580 - accuracy: 0.3221 - val_loss: 2.7235 - val_accuracy: 0.3216\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4737 - accuracy: 0.3619 - val_loss: 2.6091 - val_accuracy: 0.3474\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 2.3181 - accuracy: 0.3912 - val_loss: 2.5331 - val_accuracy: 0.3544\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 2.1861 - accuracy: 0.4211 - val_loss: 2.5100 - val_accuracy: 0.3683\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 2.0748 - accuracy: 0.4427 - val_loss: 2.5009 - val_accuracy: 0.3703\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 1.9746 - accuracy: 0.4659 - val_loss: 2.4872 - val_accuracy: 0.3786\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8756 - accuracy: 0.4893 - val_loss: 2.4952 - val_accuracy: 0.3894\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 1.7814 - accuracy: 0.5102 - val_loss: 2.5832 - val_accuracy: 0.3809\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 1.7012 - accuracy: 0.5273 - val_loss: 2.6715 - val_accuracy: 0.3736\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 1.6273 - accuracy: 0.5460 - val_loss: 2.6497 - val_accuracy: 0.3776\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 1.5438 - accuracy: 0.5663 - val_loss: 2.7162 - val_accuracy: 0.3743\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 1.4749 - accuracy: 0.5828 - val_loss: 2.7884 - val_accuracy: 0.3784\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 1.4044 - accuracy: 0.5988 - val_loss: 2.8194 - val_accuracy: 0.3735\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 1.3430 - accuracy: 0.6139 - val_loss: 2.9214 - val_accuracy: 0.3771\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2883 - accuracy: 0.6286 - val_loss: 3.0144 - val_accuracy: 0.3723\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2285 - accuracy: 0.6404 - val_loss: 3.0757 - val_accuracy: 0.3683\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.1687 - accuracy: 0.6542 - val_loss: 3.2189 - val_accuracy: 0.3709\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.1270 - accuracy: 0.6640 - val_loss: 3.2892 - val_accuracy: 0.3677\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.0777 - accuracy: 0.6791 - val_loss: 3.3835 - val_accuracy: 0.3603\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.0372 - accuracy: 0.6893 - val_loss: 3.5687 - val_accuracy: 0.3567\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.9967 - accuracy: 0.6977 - val_loss: 3.6577 - val_accuracy: 0.3541\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.9532 - accuracy: 0.7113 - val_loss: 3.8253 - val_accuracy: 0.3517\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 0.9176 - accuracy: 0.7188 - val_loss: 3.9182 - val_accuracy: 0.3500\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.8866 - accuracy: 0.7250 - val_loss: 4.0648 - val_accuracy: 0.3474\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.8526 - accuracy: 0.7374 - val_loss: 4.0943 - val_accuracy: 0.3506\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.8285 - accuracy: 0.7420 - val_loss: 4.2244 - val_accuracy: 0.3461\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.8078 - accuracy: 0.7490 - val_loss: 4.3171 - val_accuracy: 0.3506\n"
     ]
    }
   ],
   "source": [
    "# Adam Optimizer for CIFAR100 dataset\n",
    "\n",
    "model_cifar100_adam = Sequential()\n",
    "model_cifar100_adam.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model_cifar100_adam.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cifar100_adam.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_cifar100_adam.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cifar100_adam.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_cifar100_adam.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cifar100_adam.add(Flatten())\n",
    "model_cifar100_adam.add(Dense(256, activation='relu'))\n",
    "model_cifar100_adam.add(Dense(128, activation='relu'))\n",
    "model_cifar100_adam.add(Dense(100, activation='softmax'))\n",
    "\n",
    "model_cifar100_adam.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
    "\n",
    "history_adam_cifar100 = model_cifar100_adam.fit(\n",
    "    x_train, y_train, epochs=30, verbose=1, validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8263b8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 4.6042 - accuracy: 0.0107 - val_loss: 4.6018 - val_accuracy: 0.0107\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 4.5996 - accuracy: 0.0141 - val_loss: 4.5968 - val_accuracy: 0.0163\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 1067s 683ms/step - loss: 4.5918 - accuracy: 0.0168 - val_loss: 4.5852 - val_accuracy: 0.0186\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 1030s 659ms/step - loss: 4.5680 - accuracy: 0.0190 - val_loss: 4.5412 - val_accuracy: 0.0190\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 3861s 2s/step - loss: 4.4911 - accuracy: 0.0270 - val_loss: 4.4364 - val_accuracy: 0.0375\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 3550s 2s/step - loss: 4.3825 - accuracy: 0.0401 - val_loss: 4.3309 - val_accuracy: 0.0411\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 3053s 2s/step - loss: 4.2836 - accuracy: 0.0480 - val_loss: 4.2427 - val_accuracy: 0.0496\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 1059s 678ms/step - loss: 4.2160 - accuracy: 0.0559 - val_loss: 4.1966 - val_accuracy: 0.0601\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 2954s 2s/step - loss: 4.1739 - accuracy: 0.0641 - val_loss: 4.1597 - val_accuracy: 0.0716\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 4020s 3s/step - loss: 4.1411 - accuracy: 0.0710 - val_loss: 4.1337 - val_accuracy: 0.0743\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 3970s 3s/step - loss: 4.1150 - accuracy: 0.0780 - val_loss: 4.1073 - val_accuracy: 0.0820\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 4.0907 - accuracy: 0.0811 - val_loss: 4.0891 - val_accuracy: 0.0848\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 2149s 1s/step - loss: 4.0694 - accuracy: 0.0853 - val_loss: 4.0667 - val_accuracy: 0.0858\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 4.0493 - accuracy: 0.0876 - val_loss: 4.0489 - val_accuracy: 0.0898\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 4.0300 - accuracy: 0.0901 - val_loss: 4.0315 - val_accuracy: 0.0915\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 4.0119 - accuracy: 0.0930 - val_loss: 4.0145 - val_accuracy: 0.0939\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 3.9946 - accuracy: 0.0963 - val_loss: 4.0018 - val_accuracy: 0.0950\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 3.9779 - accuracy: 0.0984 - val_loss: 3.9849 - val_accuracy: 0.0958\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 3.9613 - accuracy: 0.1007 - val_loss: 3.9703 - val_accuracy: 0.1008\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 3.9453 - accuracy: 0.1042 - val_loss: 3.9539 - val_accuracy: 0.0996\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 3.9298 - accuracy: 0.1065 - val_loss: 3.9395 - val_accuracy: 0.1005\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 3.9143 - accuracy: 0.1084 - val_loss: 3.9271 - val_accuracy: 0.1049\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 3.8989 - accuracy: 0.1111 - val_loss: 3.9122 - val_accuracy: 0.1108\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 3.8832 - accuracy: 0.1140 - val_loss: 3.9031 - val_accuracy: 0.1098\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 3.8688 - accuracy: 0.1163 - val_loss: 3.8856 - val_accuracy: 0.1107\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 3.8538 - accuracy: 0.1191 - val_loss: 3.8702 - val_accuracy: 0.1177\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 3.8398 - accuracy: 0.1211 - val_loss: 3.8575 - val_accuracy: 0.1183\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 3.8255 - accuracy: 0.1248 - val_loss: 3.8472 - val_accuracy: 0.1201\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 3.8122 - accuracy: 0.1275 - val_loss: 3.8320 - val_accuracy: 0.1232\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 3.7982 - accuracy: 0.1295 - val_loss: 3.8184 - val_accuracy: 0.1254\n"
     ]
    }
   ],
   "source": [
    "# Adagrad Optimizer for CIFAR100 dataset\n",
    "\n",
    "model_adagrad_cifar100 = Sequential()\n",
    "model_adagrad_cifar100.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model_adagrad_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_adagrad_cifar100.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_adagrad_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_adagrad_cifar100.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_adagrad_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_adagrad_cifar100.add(Flatten())\n",
    "model_adagrad_cifar100.add(Dense(256, activation='relu'))\n",
    "model_adagrad_cifar100.add(Dense(128, activation='relu'))\n",
    "model_adagrad_cifar100.add(Dense(100, activation='softmax'))\n",
    "\n",
    "model_adagrad_cifar100.compile(loss='categorical_crossentropy', optimizer=Adagrad(),metrics=['accuracy'])\n",
    "\n",
    "history_adagrad_cifar100 = model_adagrad_cifar100.fit(\n",
    "    x_train, y_train, epochs=30, verbose=1, validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11179f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 1790s 1s/step - loss: 4.1744 - accuracy: 0.0620 - val_loss: 3.8696 - val_accuracy: 0.1162\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 2959s 2s/step - loss: 3.6694 - accuracy: 0.1438 - val_loss: 3.5101 - val_accuracy: 0.1686\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 745s 477ms/step - loss: 3.3743 - accuracy: 0.1926 - val_loss: 3.2962 - val_accuracy: 0.2088\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 3064s 2s/step - loss: 3.1533 - accuracy: 0.2322 - val_loss: 3.1251 - val_accuracy: 0.2420\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 2311s 1s/step - loss: 2.9839 - accuracy: 0.2652 - val_loss: 2.9922 - val_accuracy: 0.2697\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 2.8383 - accuracy: 0.2920 - val_loss: 2.9230 - val_accuracy: 0.2820\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 2.7123 - accuracy: 0.3181 - val_loss: 2.7934 - val_accuracy: 0.3152\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 2.5940 - accuracy: 0.3427 - val_loss: 2.7736 - val_accuracy: 0.3118\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 2.4901 - accuracy: 0.3625 - val_loss: 2.6404 - val_accuracy: 0.3424\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 2.3927 - accuracy: 0.3833 - val_loss: 2.5987 - val_accuracy: 0.3537\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 2.3020 - accuracy: 0.4033 - val_loss: 2.6499 - val_accuracy: 0.3452\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 2.2094 - accuracy: 0.4226 - val_loss: 2.5016 - val_accuracy: 0.3720\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 2.1360 - accuracy: 0.4414 - val_loss: 2.5103 - val_accuracy: 0.3759\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 2.0552 - accuracy: 0.4588 - val_loss: 2.4500 - val_accuracy: 0.3860\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.9811 - accuracy: 0.4732 - val_loss: 2.4521 - val_accuracy: 0.3878\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.9041 - accuracy: 0.4925 - val_loss: 2.4337 - val_accuracy: 0.3910\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 1.8323 - accuracy: 0.5070 - val_loss: 2.4708 - val_accuracy: 0.3848\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.7678 - accuracy: 0.5227 - val_loss: 2.4683 - val_accuracy: 0.3979\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.7006 - accuracy: 0.5396 - val_loss: 2.4720 - val_accuracy: 0.4038\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 1.6359 - accuracy: 0.5538 - val_loss: 2.5287 - val_accuracy: 0.3960\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.5687 - accuracy: 0.5697 - val_loss: 2.4810 - val_accuracy: 0.4036\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.5034 - accuracy: 0.5847 - val_loss: 2.5621 - val_accuracy: 0.3974\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 1.4452 - accuracy: 0.5996 - val_loss: 2.6059 - val_accuracy: 0.3966\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 1.3849 - accuracy: 0.6140 - val_loss: 2.5860 - val_accuracy: 0.4030\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 1.3273 - accuracy: 0.6288 - val_loss: 2.6679 - val_accuracy: 0.4004\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 1.2658 - accuracy: 0.6429 - val_loss: 2.6678 - val_accuracy: 0.4013\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.2144 - accuracy: 0.6555 - val_loss: 2.7475 - val_accuracy: 0.3975\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.1539 - accuracy: 0.6703 - val_loss: 2.7719 - val_accuracy: 0.4006\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.0955 - accuracy: 0.6858 - val_loss: 2.8454 - val_accuracy: 0.4003\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.0435 - accuracy: 0.7013 - val_loss: 2.8805 - val_accuracy: 0.3985\n"
     ]
    }
   ],
   "source": [
    "# Adamax Optimizer for CIFAR100 dataset\n",
    "\n",
    "model_adamax_cifar100 = Sequential()\n",
    "model_adamax_cifar100.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model_adamax_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_adamax_cifar100.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_adamax_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_adamax_cifar100.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_adamax_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_adamax_cifar100.add(Flatten())\n",
    "model_adamax_cifar100.add(Dense(256, activation='relu'))\n",
    "model_adamax_cifar100.add(Dense(128, activation='relu'))\n",
    "model_adamax_cifar100.add(Dense(100, activation='softmax'))\n",
    "\n",
    "model_adamax_cifar100.compile(loss='categorical_crossentropy', optimizer=Adamax(),metrics=['accuracy'])\n",
    "\n",
    "history_adamax_cifar100 = model_adamax_cifar100.fit(\n",
    "    x_train, y_train, epochs=30, verbose=1, validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e1e23a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 25s 15ms/step - loss: 3.8997 - accuracy: 0.1016 - val_loss: 3.4313 - val_accuracy: 0.1757\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 3.2316 - accuracy: 0.2132 - val_loss: 3.0735 - val_accuracy: 0.2360\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.8937 - accuracy: 0.2809 - val_loss: 3.0849 - val_accuracy: 0.2423\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 2.6570 - accuracy: 0.3242 - val_loss: 2.6919 - val_accuracy: 0.3241\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 2.4665 - accuracy: 0.3651 - val_loss: 2.7482 - val_accuracy: 0.3211\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 2.3180 - accuracy: 0.3973 - val_loss: 2.7660 - val_accuracy: 0.3255\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 2.1963 - accuracy: 0.4236 - val_loss: 2.6627 - val_accuracy: 0.3393\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 2.0896 - accuracy: 0.4440 - val_loss: 2.6736 - val_accuracy: 0.3661\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.9955 - accuracy: 0.4704 - val_loss: 2.5487 - val_accuracy: 0.3791\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.9127 - accuracy: 0.4857 - val_loss: 2.7708 - val_accuracy: 0.3719\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.8491 - accuracy: 0.5015 - val_loss: 2.8030 - val_accuracy: 0.3560\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.8003 - accuracy: 0.5126 - val_loss: 3.1786 - val_accuracy: 0.3423\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7669 - accuracy: 0.5228 - val_loss: 2.9954 - val_accuracy: 0.3516\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7471 - accuracy: 0.5295 - val_loss: 3.1073 - val_accuracy: 0.3657\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7346 - accuracy: 0.5329 - val_loss: 2.8970 - val_accuracy: 0.3298\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.7280 - accuracy: 0.5391 - val_loss: 2.9034 - val_accuracy: 0.3480\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7167 - accuracy: 0.5421 - val_loss: 3.4415 - val_accuracy: 0.3282\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7310 - accuracy: 0.5366 - val_loss: 3.4163 - val_accuracy: 0.3450\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7380 - accuracy: 0.5373 - val_loss: 3.1515 - val_accuracy: 0.3163\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7286 - accuracy: 0.5402 - val_loss: 3.2653 - val_accuracy: 0.3467\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7303 - accuracy: 0.5390 - val_loss: 3.3289 - val_accuracy: 0.3198\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7382 - accuracy: 0.5363 - val_loss: 3.4562 - val_accuracy: 0.3134\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7305 - accuracy: 0.5398 - val_loss: 3.4581 - val_accuracy: 0.3313\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7426 - accuracy: 0.5402 - val_loss: 3.7181 - val_accuracy: 0.3206\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.7592 - accuracy: 0.5342 - val_loss: 3.2674 - val_accuracy: 0.3242\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7656 - accuracy: 0.5351 - val_loss: 3.3578 - val_accuracy: 0.3206\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7657 - accuracy: 0.5348 - val_loss: 3.7340 - val_accuracy: 0.3145\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7675 - accuracy: 0.5362 - val_loss: 3.5227 - val_accuracy: 0.3378\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7779 - accuracy: 0.5336 - val_loss: 3.8533 - val_accuracy: 0.3255\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7780 - accuracy: 0.5336 - val_loss: 3.6701 - val_accuracy: 0.3285\n"
     ]
    }
   ],
   "source": [
    "# RMSprop Optimizer for CIFAR100 dataset\n",
    "\n",
    "model_rms_cifar100 = Sequential()\n",
    "model_rms_cifar100.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model_rms_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_rms_cifar100.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_rms_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_rms_cifar100.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_rms_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_rms_cifar100.add(Flatten())\n",
    "model_rms_cifar100.add(Dense(256, activation='relu'))\n",
    "model_rms_cifar100.add(Dense(128, activation='relu'))\n",
    "model_rms_cifar100.add(Dense(100, activation='softmax'))\n",
    "\n",
    "model_rms_cifar100.compile(loss='categorical_crossentropy', optimizer=RMSprop(),metrics=['accuracy'])\n",
    "\n",
    "history_rms_cifar100 = model_rms_cifar100.fit(\n",
    "    x_train, y_train, epochs=30, verbose=1, validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab4cf467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 3.8819 - accuracy: 0.1039 - val_loss: 3.3944 - val_accuracy: 0.1836\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 3.2249 - accuracy: 0.2141 - val_loss: 3.1277 - val_accuracy: 0.2320\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 2.8884 - accuracy: 0.2779 - val_loss: 3.0103 - val_accuracy: 0.2596\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 2.6462 - accuracy: 0.3285 - val_loss: 2.8625 - val_accuracy: 0.2951\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 2.4596 - accuracy: 0.3670 - val_loss: 2.6939 - val_accuracy: 0.3290\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 2.3040 - accuracy: 0.4003 - val_loss: 2.6894 - val_accuracy: 0.3433\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 2.1847 - accuracy: 0.4237 - val_loss: 2.6241 - val_accuracy: 0.3496\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 2.0730 - accuracy: 0.4492 - val_loss: 2.6549 - val_accuracy: 0.3523\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.9917 - accuracy: 0.4667 - val_loss: 2.6717 - val_accuracy: 0.3687\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.9175 - accuracy: 0.4855 - val_loss: 2.8077 - val_accuracy: 0.3655\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.8494 - accuracy: 0.5009 - val_loss: 2.8919 - val_accuracy: 0.3583\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.8017 - accuracy: 0.5162 - val_loss: 2.8950 - val_accuracy: 0.3609\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.7731 - accuracy: 0.5210 - val_loss: 2.8592 - val_accuracy: 0.3645\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.7565 - accuracy: 0.5277 - val_loss: 3.3921 - val_accuracy: 0.3412\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7344 - accuracy: 0.5319 - val_loss: 3.0280 - val_accuracy: 0.3670\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7165 - accuracy: 0.5374 - val_loss: 2.9280 - val_accuracy: 0.3577\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7105 - accuracy: 0.5409 - val_loss: 3.5068 - val_accuracy: 0.3515\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.6995 - accuracy: 0.5407 - val_loss: 3.6407 - val_accuracy: 0.3465\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.7013 - accuracy: 0.5448 - val_loss: 4.5712 - val_accuracy: 0.3267\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7087 - accuracy: 0.5443 - val_loss: 3.6314 - val_accuracy: 0.3314\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.7064 - accuracy: 0.5448 - val_loss: 3.5789 - val_accuracy: 0.2945\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7049 - accuracy: 0.5470 - val_loss: 3.5194 - val_accuracy: 0.3433\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7266 - accuracy: 0.5426 - val_loss: 3.2025 - val_accuracy: 0.3389\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7273 - accuracy: 0.5431 - val_loss: 3.4079 - val_accuracy: 0.3355\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.7112 - accuracy: 0.5465 - val_loss: 4.1116 - val_accuracy: 0.3428\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.7349 - accuracy: 0.5440 - val_loss: 3.5316 - val_accuracy: 0.3208\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7309 - accuracy: 0.5473 - val_loss: 3.8081 - val_accuracy: 0.3351\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7271 - accuracy: 0.5491 - val_loss: 3.4929 - val_accuracy: 0.3216\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7798 - accuracy: 0.5393 - val_loss: 3.8988 - val_accuracy: 0.3378\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7739 - accuracy: 0.5377 - val_loss: 4.2040 - val_accuracy: 0.3246\n"
     ]
    }
   ],
   "source": [
    "# SGD Optimizer for CIFAR100 dataset\n",
    "\n",
    "model_sgd_cifar100 = Sequential()\n",
    "model_sgd_cifar100.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model_sgd_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_sgd_cifar100.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_sgd_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_sgd_cifar100.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_sgd_cifar100.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_sgd_cifar100.add(Flatten())\n",
    "model_sgd_cifar100.add(Dense(256, activation='relu'))\n",
    "model_sgd_cifar100.add(Dense(128, activation='relu'))\n",
    "model_sgd_cifar100.add(Dense(100, activation='softmax'))\n",
    "\n",
    "model_sgd_cifar100.compile(loss='categorical_crossentropy', optimizer=RMSprop(),metrics=['accuracy'])\n",
    "\n",
    "history_sgd_cifar100 = model_sgd_cifar100.fit(\n",
    "    x_train, y_train, epochs=30, verbose=1, validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3f632f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_adadelta_cifar100' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory_adadelta_cifar100\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdadelta TR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history_adadelta_cifar100\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m],linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m,label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdadelta VL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history_sgd_cifar100\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSGD TR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_adadelta_cifar100' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history_adadelta_cifar100.history['loss'], label = 'Adadelta TR')\n",
    "plt.plot(history_adadelta_cifar100.history['val_loss'],linestyle=\"--\",label = 'Adadelta VL')\n",
    "\n",
    "plt.plot(history_sgd_cifar100.history['loss'], label = 'SGD TR')\n",
    "plt.plot(history_sgd_cifar100.history['val_loss'], linestyle=\"--\", label = 'SGD VL')\n",
    "\n",
    "plt.plot(history_adagrad_cifar100.history['loss'], label = 'Adagrad TR')\n",
    "plt.plot(history_adagrad_cifar100.history['val_loss'], linestyle=\"--\", label = 'Adagrad VL')\n",
    "\n",
    "plt.plot(history_adamax_cifar100.history['loss'], label = 'Adamax TR')\n",
    "plt.plot(history_adamax_cifar100.history['val_loss'], linestyle=\"--\", label = 'Adamax VL')\n",
    "\n",
    "plt.plot(history_rms_cifar100.history['loss'], label = 'RMSprop TR')\n",
    "plt.plot(history_rms_cifar100.history['val_loss'], linestyle=\"--\",  label = 'RMSprop VL')\n",
    "\n",
    "plt.plot(history_adam_cifar100.history['loss'], label = 'Adam TR')\n",
    "plt.plot(history_adam_cifar100.history['val_loss'], linestyle=\"--\", label ='Adam VL')\n",
    "\n",
    "plt.title('CIFAR100 Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.savefig('cifar100_result.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa68939",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_adadelta_cifar100.history['accuracy'], label = 'Adadelta TR')\n",
    "plt.plot(history_adadelta_cifar100.history['val_accuracy'],linestyle=\"--\",label = 'Adadelta VL')\n",
    "\n",
    "plt.plot(history_sgd_cifar100.history['accuracy'], label = 'SGD TR')\n",
    "plt.plot(history_sgd_cifar100.history['val_accuracy'], linestyle=\"--\", label = 'SGD VL')\n",
    "\n",
    "plt.plot(history_adagrad_cifar100.history['accuracy'], label = 'Adagrad TR')\n",
    "plt.plot(history_adagrad_cifar100.history['val_accuracy'], linestyle=\"--\", label = 'Adagrad VL')\n",
    "\n",
    "plt.plot(history_adamax_cifar100.history['accuracy'], label = 'Adamax TR')\n",
    "plt.plot(history_adamax_cifar100.history['val_accuracy'], linestyle=\"--\", label = 'Adamax VL')\n",
    "\n",
    "plt.plot(history_rms_cifar100.history['accuracy'], label = 'RMSprop TR')\n",
    "plt.plot(history_rms_cifar100.history['val_accuracy'], linestyle=\"--\",  label = 'RMSprop VL')\n",
    "\n",
    "plt.plot(history_adam_cifar100.history['accuracy'], label = 'Adam TR')\n",
    "plt.plot(history_adam_cifar100.history['val_accuracy'], linestyle=\"--\", label ='Adam VL')\n",
    "\n",
    "plt.title('Oxford Flowers Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(18, 12))\n",
    "# plt.savefig('caltech_result.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
